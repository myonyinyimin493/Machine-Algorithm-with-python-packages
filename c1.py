# -*- coding: utf-8 -*-
"""C1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1azfTT5fIdVvBrFttbLyfQEe_vIHXPgfA
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns

from sklearn.tree import DecisionTreeClassifier

from sklearn.model_selection import train_test_split

from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import classification_report

rawdata=pd.read_csv("CSI_6_ARI_CW_2_29.csv")
print(rawdata.shape)

rawdata.head()

rawdata.info()

rawdata.isna().sum()

rawdata[rawdata['ArrivalDelayInMinutes'].isna()]

rawdata.describe()

rawdata.dtypes

rawdata.hist(bins=60, figsize=(20,20))

raw_data=rawdata[rawdata['Age']>80]
raw_data

rawdata.plot(kind='scatter',x='Age',y='DepartureDelayInMinutes',figsize=(10,10))

plt.figure(figsize=(20,20))
sns.boxplot(x='Cleanliness',y='DepartureDelayInMinutes',data=rawdata)

rawdata[rawdata['DepartureDelayInMinutes']>500]

OnlineBooking=rawdata[rawdata['LegRoomService']==0]
OnlineBooking

from enum import unique
for column in rawdata:
  unique_values =np.unique(rawdata[column])
  nr_values = len(unique_values)
  if nr_values<=10:
   print("The number of values for feature {} is:{} -- {}".format(column,nr_values,unique_values))
  else:
    print("The number of values for feature {} is:{}".format(column,nr_values))

g= sns.pairplot(rawdata)

rawdata['FoodAndDrink'].value_counts()

rawdata['InflightEntertainment'].value_counts()

rawdata['Cleanliness'].value_counts()

rawdata.plot(kind='scatter',x='Age',y='ArrivalDelayInMinutes',figsize=(10,10))

rawdata.columns

"""Data Cleaning (Deleting Outlier)"""

ArrivalDelay=rawdata[rawdata['ArrivalDelayInMinutes']>500]
ArrivalDelay

rawdata.plot(kind='scatter',x='Age',y='ArrivalDelayInMinutes',figsize=(10,10))

rawdata=rawdata[(rawdata['ArrivalDelayInMinutes']<500) & (rawdata['Age']<80)& (rawdata['DepartureDelayInMinutes']<500)]
rawdata.shape

g=sns.pairplot(rawdata)

rawdata.plot(kind='scatter',x='OnlineBoarding',y='EaseOfOnlineBooking',figsize=(10,10))

FlightD=rawdata[rawdata['FlightDistance']>4000]
FlightD

rawdata.shape

rawdata1=rawdata[(rawdata['FlightDistance']<4000)]
rawdata1.shape

g=sns.pairplot(rawdata1)

rawdata1['InflightEntertainment'].value_counts()

rawdata1['FoodAndDrink']=rawdata1['FoodAndDrink'].replace([0],1)

rawdata1['FoodAndDrink'].value_counts()

rawdata1['Cleanliness'].value_counts()

rawdata1['Cleanliness']=rawdata1['Cleanliness'].replace([0],1)

rawdata1['Cleanliness'].value_counts()

rawdata1['LegRoomService'].value_counts()

rawdata1['InflightEntertainment']=rawdata1['InflightEntertainment'].replace([0],1)

rawdata1['InflightEntertainment'].value_counts()

rawdata1.shape

rawdata1.describe()

rawdata1['ArrivalDelayInMinutes'].fillna(value=rawdata1['ArrivalDelayInMinutes'].mean(), inplace=True)

rawdata1[rawdata1['ArrivalDelayInMinutes'].isna()]

rawdata1.info()

g= sns.pairplot(rawdata1)

sns.countplot(x='satisfaction',data=rawdata1,palette='Set3')

rawdata1.columns

features =['Gender', 'CustomerType', 'TypeOfTravel', 'Class','InflightWifiService',
       'DepartureArrivalTimeConvenient', 'EaseOfOnlineBooking', 'GateLocation',
       'FoodAndDrink', 'OnlineBoarding', 'SeatComfort',
       'InflightEntertainment', 'OnboardService', 'LegRoomService',
       'BaggageHandling', 'CheckinService', 'InflightService', 'Cleanliness']

for f in features:
  sns.countplot(x=f,data=rawdata1,palette='Set3',hue = 'satisfaction')
  plt.show()

rawdata1.head()

new_raw_data=pd.get_dummies(rawdata1, columns=features)
new_raw_data

print(rawdata1.shape)
print(new_raw_data.shape)

new_raw_data['satisfaction'][new_raw_data['satisfaction'] == 'satisfied']=1
new_raw_data['satisfaction'][new_raw_data['satisfaction'] == 'neutral or dissatisfied']=0

new_raw_data

x=new_raw_data.drop('satisfaction', axis=1).values
y= new_raw_data['satisfaction']

y=y.astype(int)
print(x.shape)
print(y.shape)

from pandas.core.common import random_state
dt=DecisionTreeClassifier(random_state=15,criterion='entropy', max_depth=10)
dt.fit(x,y)

fi_col =[]
fi = []

for i,column in enumerate(new_raw_data.drop('satisfaction', axis=1)):
  print("The feature important for{} is: {}".format(column, dt.feature_importances_[i]))

  fi_col.append(column)
  fi.append(dt.feature_importances_[i])

fi_col
fi

fi_df =zip(fi_col,fi)
fi_df = pd.DataFrame(fi_df,columns =['Feature','Feature_Important'])
fi_df

fi_df=fi_df.sort_values('Feature_Important', ascending=False).reset_index()

fi_df

columns_to_keep=fi_df['Feature'][0:60]

columns_to_keep

print(new_raw_data.shape)
print(new_raw_data[columns_to_keep].shape)

x=new_raw_data[columns_to_keep].values
x

y= new_raw_data['satisfaction']
y

y=y.astype(int)
y

print(x.shape)
print(y.shape)

x_train, x_test, y_train, y_test= train_test_split(x,y,train_size=0.8, test_size=0.2,random_state=15)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

ax= sns.countplot(x=y_test, palette="Set3")

log_reg = LogisticRegression(random_state=0, solver='lbfgs')
log_reg.fit(x_train,y_train)

log_reg.predict(x_train)
y_pred=log_reg.predict(x_train)

y_pred

pred_proba=log_reg.predict_proba(x_train)

pred_proba

log_reg.coef_.shape

print("The Training Accuracy is",log_reg.score(x_train,y_train))

print("The Testing Accuracy is",log_reg.score(x_test,y_test))

print(classification_report(y_train,y_pred))

from sklearn.metrics import confusion_matrix

cm=confusion_matrix(y_train,y_pred)

cm

from seaborn.matrix import heatmap
def plot_confusion_matrix(cm,classes=None,title='Confusion matrix'):
  """Plots a confusion matrix"""
  if classes is not None:
      sns.heatmap(cm,xticklabels=classes,yticklabels=classes,vmin=0.,vmax=1,annot=True,annot_kws={'size':50})
  else:
      sns.heatmap(cm,vmin=0.,vmax=1.)
      plt.title(title)
      plt.ylable('True label')
      plt.xlabel('Predicted label')

cm=confusion_matrix(y_train,y_pred)
cm_norm=cm /cm.sum(axis=1).reshape(-1,1)
plot_confusion_matrix(cm_norm, classes=log_reg.classes_,title='Confusion matrix')

from sklearn.metrics import log_loss

print("The log lost on training dataset is :",log_loss(y_train,pred_proba))

pred_proba_test=log_reg.predict_proba(x_test)
print("The log lost on testing dataset is :",log_loss(y_test,pred_proba_test))

from sklearn.linear_model import LogisticRegressionCV
C_List = np.geomspace(1e-5, 1e5, num=20)
Log_reg3 = LogisticRegressionCV(random_state=15, Cs = C_List, solver ='lbfgs')
Log_reg3.fit(x_train, y_train)
print("The Classification Accuracy is:", Log_reg3.score(x_test, y_test))
pred_proba_t = Log_reg3.predict_proba(x_test)
log_loss3 = log_loss(y_test, pred_proba_t)
print("The Logistic Loss is: ", log_loss3)

print("The optimal C parameter is: ", Log_reg3.C_)

log_reg3 = LogisticRegression(random_state=10, solver = 'lbfgs', C=233.57214691)
log_reg3.fit(x_train, y_train)
score = log_reg3.score(x_test, y_test)

pred_proba_t = log_reg3.predict_proba(x_test)
log_loss2 = log_loss(y_test, pred_proba_t)

print("Testing Accuracy:", score)
print("Log Loss:", log_loss2)

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

scaled_X_train = scaler.fit_transform(x_train) 
scaled_X_test = scaler.transform(x_test)

knn_model = KNeighborsClassifier(n_neighbors=1)
 knn_model.fit(scaled_X_train,y_train)

y_pred = knn_model.predict(scaled_X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred)

1-accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

from sklearn.model_selection import GridSearchCV

scaler = StandardScaler()
knn = KNeighborsClassifier()

knn.get_params().keys()

operations = [('scaler',scaler),('knn',knn)] 
 print(operations)

from sklearn.pipeline import Pipeline
pipe = Pipeline(operations) 
print(pipe)

k_values = list(range(1,30))
param_grid = {'knn__n_neighbors': k_values} 
print(param_grid)

full_cv_classifier = GridSearchCV(pipe,param_grid,cv=5,scoring='accuracy') 
 full_cv_classifier.fit(x_train,y_train)

full_cv_classifier.best_estimator_.get_params()

full_cv_classifier.cv_results_['mean_test_score']

scaler = StandardScaler()
knn5 = KNeighborsClassifier(n_neighbors=5) 
operations = [('scaler',scaler),('knn5',knn5)]

pipe = Pipeline(operations) 
 pipe.fit(x_train,y_train) 
 pipe_pred = pipe.predict(x_test)

accuracy_score(y_test,pipe_pred)

1 - accuracy_score(y_test,pipe_pred)